{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/DarthReca/RL-exercises.git\n",
    "    !pip install gymnasium pytorch-lightning comet_ml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from models import DQNAgent, ReplayBuffer\n",
    "from random import random\n",
    "from lightning_lite.utilities.seed import seed_everything\n",
    "import comet_ml as cml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 45\n"
     ]
    },
    {
     "data": {
      "text/plain": "45"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(45)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_env = gym.make(\"LunarLander-v2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"state_dim\": train_env.observation_space.shape[0],\n",
    "    \"action_dim\": train_env.action_space.shape[0],\n",
    "    \"net_width\": 200,\n",
    "    \"batch_size\": 512,\n",
    "    \"gamma\": 0.5,\n",
    "    \"exp_noise\":  0.2,\n",
    "    \"env_with_dw\": True,\n",
    "    \"DDQN\": False\n",
    "}\n",
    "agent = DQNAgent(**args)\n",
    "buffer = ReplayBuffer(args[\"state_dim\"], max_size=1e6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def epsilon_greedy(env: gym.Env, state, epsilon: float):\n",
    "    if random() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    return agent.select_action(state, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "STEPS_BEFORE_TRAINING = 10000\n",
    "LEARNING_FREQUENCY = 500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment = cml.Experiment(api_key=\"\", workspace=\"darthreca\", project_name=\"LunarLander\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment.log_parameters(args)\n",
    "experiment.log_parameters({\n",
    "    \"warming_steps\": STEPS_BEFORE_TRAINING,\n",
    "    \"learning_frequency\": LEARNING_FREQUENCY\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "steps = 0\n",
    "for episode in range(10000):\n",
    "    obs, _ = train_env.reset()\n",
    "    term, trunc = False, False\n",
    "    episode_reward, episode_length = 0, 0\n",
    "    while not (term or trunc):\n",
    "        # Take action and add to buffer\n",
    "        action = epsilon_greedy(train_env, obs, 1)\n",
    "        next_obs, reward, term, trunc, _ = train_env.step(action)\n",
    "        buffer.add(obs, action, reward, next_obs, term or trunc)\n",
    "        # Learn\n",
    "        if steps > STEPS_BEFORE_TRAINING and steps % LEARNING_FREQUENCY == 0:\n",
    "            for i in range(LEARNING_FREQUENCY):\n",
    "                agent.train(buffer, i)\n",
    "        # Updated accumulated metrics\n",
    "        episode_length += 1\n",
    "        episode_reward += reward\n",
    "        # Update\n",
    "        obs = next_obs\n",
    "        steps += 1\n",
    "    metrics = {\"episode_reward\": episode_reward, \"episode_length\": episode_length}\n",
    "    experiment.log_metrics(metrics, steps=steps, epoch=episode)\n",
    "experiment.end()\n",
    "train_env.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
